[
{
	"uri": "/3-accessibilitytoinstances/3.1-public-instance/",
	"title": "Connect to Public Instance",
	"tags": [],
	"description": "",
	"content": " Go to EC2 service management console.   Click on Public Linux Instance. Click Actions. Click Security. Click Modify IAM role.  At the Modify IAM role page.   Click to select SSM-Role. Click Save.  You will need to wait about 10 minutes before performing the next step. This time our EC2 instance will automatically register with the Session Manager.\n\rGo to the AWS Systems Manager service management console   Drag the left menu slider down. Click Session Manager. Click Start Session.  Then select Public Linux Instance and click Start session to access the instance.  Terminal will appear on the browser. Testing with the command sudo tcpdump -nn port 22 and sudo tcpdump  we will see no SSH traffic but only HTTPS traffic.  Above, we have created a connection to the public instance without opening SSH port 22, for better security, avoiding any attack to the SSH port.\nOne disadvantage of the above method is that we have to open the Security Group outbound at port 443 to the internet. Since it\u0026rsquo;s a public instance, it probably won\u0026rsquo;t be a problem, but if you want extra security, you can block port 443 to the internet and still use the Session Manager. We will go through this in the private instance section below.\n\rYou can click terminate to end the currently connected session before proceeding to the next step.\n"
},
{
	"uri": "/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/3.2.2.1-endpointssm/",
	"title": "Create Endpoint ssm",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint SSM  Go to VPC service management console   Click Endpoints. Click Create endpoint.  At the Create endpoint page.   In the Name tag field, enter SSM. In the Service Category section, select AWS Services. In the Service Name section, In the Service category section, select: AWS services In the Service Name section enter: SSM then select Service Name: com.amazonaws.ap-southeast-1.ssm.  In the Service Name column, click com.amazonaws.ap-southeast-1.ssm.   In the VPC section, select Lab VPC. Select the first AZ, then select the Lab Private Subnet subnet.  Scroll down.   In the Security Group section, select the Security group SG VPC Endpoint that we created earlier. In the Policy section, select Full access.  Scroll down.   Click Create endpoint.  We have created the VPC Interface Endpoint for SSM.  "
},
{
	"uri": "/2-prerequiste/2.1-createec2/2.1.1-createvpc/",
	"title": "Create VPC",
	"tags": [],
	"description": "",
	"content": "Create VPC Lab VPC  Go to VPC service management console  Click Your VPC. Click Create VPC.    At the Create VPC page.  In the Name tag field, enter Lab VPC. In the IPv4 CIDR field, enter: 10.10.0.0/16. Click Create VPC.    "
},
{
	"uri": "/",
	"title": "E-commerce Microservices on AWS",
	"tags": [],
	"description": "",
	"content": "Building E-commerce System with Microservices Architecture on AWS Overall In this comprehensive workshop, you\u0026rsquo;ll learn how to design and implement a scalable e-commerce system using microservices architecture on AWS. You\u0026rsquo;ll build a complete solution featuring multiple services including supplier service, consumer service, inventory service, product service, payment service, and order service, all orchestrated through an API gateway with service discovery and configuration management.\nThe architecture includes:\n API Gateway: Central entry point for all client requests Service Discovery: Automatic service registration and discovery Configuration Server: Centralized configuration management Core Services: Supplier, Consumer, Inventory, Product, Payment, and Order services AWS Cognito: User authentication and authorization Container Orchestration: Microservices deployment using containers AWS CDK: Infrastructure as Code for automated deployment  What you\u0026rsquo;ll learn:  Deploy infrastructure using AWS CDK (TypeScript) Build and containerize microservices Implement service-to-service communication Set up centralized configuration and service discovery Monitor and log distributed applications  Content  Introduction to Microservices Architecture CDK Infrastructure Setup Deploy Core Services Service Communication \u0026amp; Discovery Clean up resources  "
},
{
	"uri": "/3-accessibilitytoinstances/3.2-private-instance/3.2.1-enablevpcdns/",
	"title": "Enable DNS hostnames",
	"tags": [],
	"description": "",
	"content": "Enable DNS hostnames on VPC.  To create VPC Endpoint we will need to enable DNS hostnames feature on VPC.    Go to VPC service management console\n  Click Your VPCs.\n  Select Lab VPC.\n  Click Actions.\n  Click Edit DNS hostnames.\n  Click Endpoint, then click Create Endpoint.\n  At the Edit DNS hostnames page.  Click to select Enable. Click Save changes.    "
},
{
	"uri": "/1-introduce/",
	"title": "Introduction to Microservices Architecture",
	"tags": [],
	"description": "",
	"content": "What is Microservices Architecture? Microservices architecture is a software development approach where a large application is built as a suite of small, independent services that communicate over well-defined APIs. Each service is focused on a specific business capability and can be developed, deployed, and scaled independently.\nBenefits of Microservices on AWS By implementing microservices architecture on AWS, you gain the following advantages:\n Scalability: Each service can be scaled independently based on demand Technology Diversity: Different services can use different programming languages and databases Fault Isolation: Failure in one service doesn\u0026rsquo;t bring down the entire application Faster Development: Teams can work independently on different services Easier Maintenance: Smaller codebases are easier to understand and maintain Continuous Deployment: Services can be deployed independently without affecting others  E-commerce System Components In our e-commerce microservices system, we\u0026rsquo;ll implement the following core services:\nCore Business Services  Supplier Service: Manages supplier information and vendor relationships Consumer Service: Handles customer profiles and preferences Inventory Service: Tracks product stock levels and availability Product Service: Manages product catalog and information Payment Service: Processes payment transactions securely Order Service: Handles order lifecycle management  Infrastructure Components  API Gateway: Single entry point for all client requests Service Discovery: Automatic service registration and location Configuration Server: Centralized configuration management AWS Cognito: User authentication and authorization  AWS Services We\u0026rsquo;ll Use Throughout this workshop, we\u0026rsquo;ll leverage various AWS services:\n Amazon ECS/EKS: Container orchestration AWS ALB: Application Load Balancer for traffic distribution Amazon ECR: Container registry for Docker images AWS CloudWatch: Monitoring and logging Amazon VPC: Network isolation and security AWS IAM: Identity and access management  "
},
{
	"uri": "/2-prerequiste/2.1-createec2/",
	"title": "Preparing Container Infrastructure",
	"tags": [],
	"description": "",
	"content": "In this step, we will create the foundational infrastructure for our microservices deployment. This includes setting up a VPC with proper networking, container orchestration platform (ECS/EKS), and the necessary compute resources.\nOur infrastructure will support the following microservices:\n Supplier Service: Manages vendor relationships and supplier data Consumer Service: Handles customer information and preferences Inventory Service: Tracks product availability and stock levels Product Service: Manages product catalog and metadata Payment Service: Processes payment transactions securely Order Service: Handles order lifecycle and fulfillment  Infrastructure Components: 1. VPC and Networking  VPC: Isolated network environment for our microservices Public Subnets: For load balancers and API Gateway Private Subnets: For microservices and databases NAT Gateway: For outbound internet access from private subnets Security Groups: Fine-grained access control between services  2. Container Platform  Amazon ECS: Managed container orchestration service ECS Clusters: Logical grouping of compute resources Task Definitions: Blueprint for running containers Services: Ensure desired number of tasks are running  3. Service Discovery  AWS Cloud Map: Service discovery for microservices DNS-based Discovery: Automatic service endpoint resolution Health Checks: Monitor service availability  Content  Create VPC and Networking Setup Public Subnets Setup Private Subnets Configure Security Groups Create ECS Cluster Setup Service Discovery Create VPC Create Public Subnet Create Private Subnet Create security group Create public Linux server Create private Windows server  "
},
{
	"uri": "/4-s3log/4.1-updateiamrole/",
	"title": "Update IAM Role",
	"tags": [],
	"description": "",
	"content": "For our EC2 instances to be able to send session logs to the S3 bucket, we will need to update the IAM Role assigned to the EC2 instance by adding a policy that allows access to S3.\nUpdate IAM Role  Go to IAM service management console   Click Roles. In the search box, enter SSM. Click on the SSM-Role role.  Click Attach policies.  In the Search box enter S3.   Click the policy AmazonS3FullAccess. Click Attach policy.  In the production environment, we will grant stricter permissions to the specified S3 bucket. In the framework of this lab, we use the policy AmazonS3FullAccess for convenience.\n\rNext, we will proceed to create an S3 bucket to store session logs.\n"
},
{
	"uri": "/2-prerequiste/",
	"title": "CDK Infrastructure Setup",
	"tags": [],
	"description": "",
	"content": "\rIn this section, we\u0026rsquo;ll use AWS CDK (Cloud Development Kit) to define and deploy our microservices infrastructure as code. CDK allows us to define cloud resources using familiar programming languages and ensures consistent, repeatable deployments.\n\rPrerequisites Before starting, ensure you have:\n AWS CLI: Configured with appropriate permissions Node.js: Version 16 or later AWS CDK: Latest version installed (npm install -g aws-cdk) Docker: For building container images Basic TypeScript knowledge: CDK stacks will be written in TypeScript  Infrastructure Overview Our CDK application will create:\n VPC with Public/Private Subnets: Network isolation for services ECS Fargate Cluster: Serverless container hosting ECR Repositories: Container image storage API Gateway: HTTP API for service access Service Discovery: AWS Cloud Map for inter-service communication IAM Roles \u0026amp; Policies: Secure access management CloudWatch: Logging and monitoring  CDK Project Structure ecommerce-microservices-cdk/\r├── bin/\r│ └── app.ts # CDK App entry point\r├── lib/\r│ ├── network-stack.ts # VPC, subnets, security groups\r│ ├── ecr-stack.ts # Container repositories\r│ ├── ecs-stack.ts # ECS cluster and services\r│ ├── api-gateway-stack.ts # API Gateway configuration\r│ └── monitoring-stack.ts # CloudWatch setup\r├── services/\r│ ├── product-service/ # Product microservice\r│ ├── order-service/ # Order microservice\r│ ├── payment-service/ # Payment microservice\r│ ├── inventory-service/ # Inventory microservice\r│ ├── supplier-service/ # Supplier microservice\r│ └── consumer-service/ # Consumer microservice\r├── cdk.json\r└── package.json\rKey Benefits of CDK for Microservices:  Infrastructure as Code: Version control your infrastructure Type Safety: Catch errors at compile time Reusable Constructs: Share infrastructure patterns Cross-Stack References: Easy integration between services Automated Rollbacks: Safe deployment practices  Content  Initialize CDK Project Setup IAM Roles and Policies  "
},
{
	"uri": "/3-accessibilitytoinstances/3.2-private-instance/",
	"title": "Connect to Private instance",
	"tags": [],
	"description": "",
	"content": "For Windows instance located in private subnet, there is no public IP, no internet gateway so it cannot go out internet.\nWith this type of instance, the traditional way is to use Bastion host technique which is expensive and laborious, but here we will use Session Manager with this type.\nBasically, the private instance still has to open the TCP 443 port to System Manager, but we don\u0026rsquo;t want to allow connection go out to the internet, but only in its VPC, to enhance our security posture.\nTo do that, we have to include the System Manager endpoint in the VPC, that is, using the VPC interface endpoint:\nVPC interface endpoint is attached to the subnet, so this method can be done not only with private subnet but also with public subnet, meaning that with public subnet, you can completely prohibit TCP 443 go out to the internet.\nContent:  Enable DNS hostnames Create VPC Endpoint Connect Private Instance  "
},
{
	"uri": "/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/3.2.2.2-endpointssmmessages/",
	"title": "Create Endpoint ssmmessages",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint SSMMESSAGES  Go to VPC service management console   Click Endpoints. Click Create endpoint.  At the Create endpoint page.   In the Name tag field, enter SSMMESSAGES. In the Service Category section, select AWS Services. In the Service Name section, In the Service category select: AWS services In the Service Name field enter: ssmmessages then select Service Name: com.amazonaws.ap-southeast-1.ssmmessages.  In the Service Name column, click com.amazonaws.ap-southeast-1.ssmmessages.   In the VPC section, select Lab VPC. Select the first AZ, then select the Lab Private Subnet subnet.  Scroll down.   In the Security Group section, select the Security group SG VPC Endpoint that we created earlier. In the Policy section, select Full access  Scroll down.   Click Create endpoint.  We have created the VPC Interface Endpoint SSMMESSAGES.  "
},
{
	"uri": "/2-prerequiste/2.2-createiamrole/",
	"title": "Create IAM Role",
	"tags": [],
	"description": "",
	"content": "Create IAM Role In this step, we will proceed to create IAM Role. In this IAM Role, the policy AmazonSSMManagedInstanceCore will be assigned, this is the policy that allows the EC2 server to communicate with the Session Manager.\n Go to IAM service administration interface In the left navigation bar, click Roles.  Click Create role.  Click AWS service and click EC2.   Click Next: Permissions.  In the Search box, enter AmazonSSMManagedInstanceCore and press Enter to search for this policy.   Click the policy AmazonSSMManagedInstanceCore. Click Next: Tags.  Click Next: Review. Name the Role SSM-Role in Role Name   Click Create Role .  Next, we will make the connection to the EC2 servers we created with Session Manager.\n"
},
{
	"uri": "/2-prerequiste/2.1-createec2/2.1.2-createpublicsubnet/",
	"title": "Create Public Subnet",
	"tags": [],
	"description": "",
	"content": "Create Public Subnet  Click Subnets.   Click Create subnet.  At the Create subnet page.   In the VPC ID section, click Lab VPC. In the Subnet name field, enter Lab Public Subnet. In the Availability Zone section, select the first Availability zone. In the field IPv4 CIRD block enter 10.10.1.0/24.   Scroll to the bottom of the page, click Create subnet.\n  Click Lab Public Subnet.\n   Click Actions. Click Edit subnet settings.  Click Enable auto-assign public IPv4 address.   Click Save.  Click Internet Gateways.   Click Create internet gateway.  At the Create internet gateway page.   In the Name tag field, enter Lab IGW. Click Create internet gateway.  After successful creation, click Actions.   Click Attach to VPC.  At the Attach to VPC page.   In the Available VPCs section, select Lab VPC. Click Attach internet gateway. Check the successful attaching process as shown below.  Next we will create a custom route table to assign to Lab Public Subnet.   Click Route Tables. Click Create route table.  At the Create route table page.   In the Name field, enter Lab Publicrtb. In the VPC section, select Lab VPC. Click Create route table.  After creating the route table successfully.   Click Edit routes.  At the Edit routes page.   Click Add route. In the Destination field, enter 0.0.0.0/0 In the Target section, select Internet Gateway and then select Lab IGW. Click Save changes.  Click the Subnet associations tab.   Click Edit subnet associations to proceed with the associate custom route table we just created in Lab Public Subnet.  At the Edit subnet associations page.   Click on Lab Public Subnet. Click Save associations.  Check that the route table information has been associated with Lab Public Subnet and the internet route information has been pointed to the Internet Gateway as shown below.  "
},
{
	"uri": "/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/",
	"title": "Create VPC Endpoint",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint SSM We will create 3 interface endpoints required by the Session Manager:\n Interface endpoints:  com.amazonaws.region.ssm com.amazonaws.region.ec2messages com.amazonaws.region.ssmmessages    You can refer to more here\nContent:  Create Endpoint ssm Create Endpoint ssmmessages Create Endpoint ec2messages  "
},
{
	"uri": "/4-s3log/4.2-creates3bucket/",
	"title": "Setting up API Gateway",
	"tags": [],
	"description": "",
	"content": "API Gateway Configuration for E-commerce Microservices In this section, we\u0026rsquo;ll configure Amazon API Gateway as the single entry point for our e-commerce microservices system. The API Gateway will route requests to the appropriate microservices using service discovery.\nCDK Implementation for API Gateway // lib/stacks/api-gateway-stack.ts import { Stack, StackProps } from \u0026#39;aws-cdk-lib\u0026#39;; import { HttpApi, HttpMethod, CorsHttpMethod } from \u0026#39;@aws-cdk/aws-apigatewayv2-alpha\u0026#39;; import { HttpServiceDiscoveryIntegration } from \u0026#39;@aws-cdk/aws-apigatewayv2-integrations-alpha\u0026#39;; import { VpcLink } from \u0026#39;@aws-cdk/aws-apigatewayv2-alpha\u0026#39;; import { Construct } from \u0026#39;constructs\u0026#39;; export class ApiGatewayStack extends Stack { public readonly httpApi: HttpApi; constructor(scope: Construct, id: string, props: ApiGatewayStackProps) { super(scope, id, props); // VPC Link for private integration  const vpcLink = new VpcLink(this, \u0026#39;EcommerceVpcLink\u0026#39;, { vpc: props.vpc, description: \u0026#39;VPC Link for e-commerce microservices\u0026#39;, }); // HTTP API Gateway  this.httpApi = new HttpApi(this, \u0026#39;EcommerceApi\u0026#39;, { apiName: \u0026#39;ecommerce-microservices-api\u0026#39;, description: \u0026#39;HTTP API for e-commerce microservices\u0026#39;, corsPreflight: { allowOrigins: [\u0026#39;*\u0026#39;], allowMethods: [CorsHttpMethod.ANY], allowHeaders: [\u0026#39;*\u0026#39;], }, }); // Add routes for each service  this.addServiceRoutes(vpcLink, props.services); } private addServiceRoutes(vpcLink: VpcLink, services: ServiceInfo[]) { const routes = [ { path: \u0026#39;products\u0026#39;, service: \u0026#39;product-service\u0026#39; }, { path: \u0026#39;inventory\u0026#39;, service: \u0026#39;inventory-service\u0026#39; }, { path: \u0026#39;orders\u0026#39;, service: \u0026#39;order-service\u0026#39; }, { path: \u0026#39;payments\u0026#39;, service: \u0026#39;payment-service\u0026#39; }, { path: \u0026#39;suppliers\u0026#39;, service: \u0026#39;supplier-service\u0026#39; }, { path: \u0026#39;consumers\u0026#39;, service: \u0026#39;consumer-service\u0026#39; }, ]; routes.forEach(route =\u0026gt; { const integration = new HttpServiceDiscoveryIntegration( `${route.service}Integration`, services.find(s =\u0026gt; s.name === route.service)?.cloudMapService!, { vpcLink, } ); this.httpApi.addRoutes({ path: `/api/v1/${route.path}/{proxy+}`, methods: [HttpMethod.ANY], integration, }); }); } } API Routes Structure Our API Gateway routes requests based on URL paths:\nGET /api/v1/products/* → product-service.ecommerce.local\rGET /api/v1/inventory/* → inventory-service.ecommerce.local POST /api/v1/orders/* → order-service.ecommerce.local\rPOST /api/v1/payments/* → payment-service.ecommerce.local\rGET /api/v1/suppliers/* → supplier-service.ecommerce.local\rGET /api/v1/consumers/* → consumer-service.ecommerce.local\rTesting the API Gateway After deployment, you can test the endpoints:\n# Get API Gateway URL from CDK output export API_URL=$(aws cloudformation describe-stacks \\  --stack-name ApiGatewayStack \\  --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue\u0026#39; \\  --output text) # Test product service curl -X GET \u0026#34;${API_URL}/api/v1/products\u0026#34; # Test with specific product ID curl -X GET \u0026#34;${API_URL}/api/v1/products/123\u0026#34; # Create a new order curl -X POST \u0026#34;${API_URL}/api/v1/orders\u0026#34; \\  -H \u0026#34;Content-Type: application/json\u0026#34; \\  -d \u0026#39;{ \u0026#34;customerId\u0026#34;: \u0026#34;customer-123\u0026#34;, \u0026#34;items\u0026#34;: [ { \u0026#34;productId\u0026#34;: \u0026#34;product-456\u0026#34;, \u0026#34;quantity\u0026#34;: 2, \u0026#34;price\u0026#34;: 29.99 } ] }\u0026#39; Monitoring API Gateway Enable logging and monitoring:\n// Add to API Gateway stack import { LogGroup } from \u0026#39;aws-cdk-lib/aws-logs\u0026#39;; const accessLogGroup = new LogGroup(this, \u0026#39;ApiGatewayAccessLogs\u0026#39;, { logGroupName: \u0026#39;/aws/apigateway/ecommerce-api\u0026#39;, retention: RetentionDays.ONE_WEEK, }); this.httpApi.addStage(\u0026#39;prod\u0026#39;, { stageName: \u0026#39;prod\u0026#39;, autoDeploy: true, accessLogSettings: { destinationArn: accessLogGroup.logGroupArn, format: JSON.stringify({ requestId: \u0026#39;$context.requestId\u0026#39;, requestPath: \u0026#39;$context.path\u0026#39;, requestMethod: \u0026#39;$context.httpMethod\u0026#39;, responseLatency: \u0026#39;$context.responseLatency\u0026#39;, status: \u0026#39;$context.status\u0026#39;, }), }, }); Security Considerations For production environments, consider adding:\n API Keys for rate limiting JWT Authorizers for authentication WAF for security protection Request validation for input sanitization  Next Steps After setting up the API Gateway:\n Deploy the stack: cdk deploy ApiGatewayStack Test all service endpoints Configure monitoring and alerting Set up authentication if needed   In the Region section, select Region you are doing the current lab.  The name of the S3 bucket must not be the same as all other S3 buckets in the system. You can substitute your name and enter a random number when generating the S3 bucket name.\n\rScroll down and click Create bucket.  When we created the S3 bucket we did Block all public access so our EC2 instances won\u0026rsquo;t be able to connect to S3 via the internet. In the next step, we will configure the S3 Gateway Endpoint feature to allow EC2 instances to connect to the S3 bucket via the VPC\u0026rsquo;s internal network.\n\r"
},
{
	"uri": "/3-accessibilitytoinstances/3.2-private-instance/3.2.3-connectec2/",
	"title": "Connect to instance",
	"tags": [],
	"description": "",
	"content": "Assign IAM role and restart EC2 instance.  Go to EC2 service management console   Click Private Windows Instance. Click Actions. Click Security. Click Modify IAM Role.  At the Modify IAM Role page.   In the IAM role section, select SSM-Role. Click Save.  Click Private Windows Instance.   Click Instance state. Click Reboot instance to restart, then click Reboot to confirm.  Please wait 5 minutes before doing the next step.\n\rConnect to the private EC2 instance.  Go to System Manager - Session Manager service management console   Click Start session.  Click Private Windows Instance.   Click Start session.  Type ipconfig command to check the IP address information of Private Windows Instance as shown below.  "
},
{
	"uri": "/3-accessibilitytoinstances/3.2-private-instance/3.2.2-createvpcendpoint/3.2.2.3-endpointec2messages/",
	"title": "Create Endpoint ec2messages",
	"tags": [],
	"description": "",
	"content": "Create VPC Endpoint EC2MESSAGES  Go to VPC service management console   Click Endpoints. Click Create endpoint.  At the Create endpoint page.   In the Name tag field, enter SSMMESSAGES. In the Service Category section, select AWS Services. In the Service Name section, In the Service category select: AWS services In the field Service Name enter: ec2 then select Service Name: com.amazonaws.ap-southeast-1.ec2messages.  In the Service Name column, click com.amazonaws.ap-southeast-1.ec2messages.   In the VPC section, select Lab VPC. Select the first AZ, then select the Lab Private Subnet subnet.  Scroll down.   In the Security Group section, select the Security group SG VPC Endpoint that we created earlier. In the Policy section, select Full access  Scroll down.   Click Create endpoint.   We have created the VPC Interface Endpoint EC2MESSAGES.\n  Make sure the 3 required endpoints have been created as shown below.\n  "
},
{
	"uri": "/2-prerequiste/2.1-createec2/2.1.3-createprivatesubnet/",
	"title": "Create Private Subnet",
	"tags": [],
	"description": "",
	"content": "Create Private Subnet  Click Subnets.  Click Create subnet.    At the Create subnet page.  In the VPC ID section, click Lab VPC. In the Subnet name field, enter Lab Private Subnet. In the Availability Zone section, select the first Availability zone. In the field IPv4 CIRD block enter 10.10.2.0/24.    Scroll to the bottom of the page, click Create subnet.  The next step is to create the necessary security groups for the lab.\n"
},
{
	"uri": "/4-s3log/4.3-creategwes3/",
	"title": "Create S3 Gateway endpoint",
	"tags": [],
	"description": "",
	"content": " Go to VPC service management console   Click Endpoints. Click Create endpoint.  At the Create endpoint page.   In the Name tag field, enter S3GW. In the Service Category section, click AWS services. In the search box enter S3, then select com.amazonaws.[region].s3  In the Services section, select com.amazonaws.[region].s3 with the Type of Gateway.   In the VPC section, select Lab VPC. In the Route tables section, select both route tables.  Scroll down, click Create endpoint.  The next step is to configure Session Manager to store session logs to the S3 bucket we created.\n"
},
{
	"uri": "/3-accessibilitytoinstances/",
	"title": "Deploy Core Services",
	"tags": [],
	"description": "",
	"content": "In this section, we\u0026rsquo;ll deploy our core microservices using the CDK infrastructure we set up. Each service will be containerized and deployed to ECS Fargate for scalable, serverless container hosting.\nCore Services Overview Our e-commerce platform consists of six main microservices:\n Product Service: Manages product catalog, categories, and pricing Inventory Service: Tracks stock levels and availability Order Service: Handles order lifecycle and fulfillment Payment Service: Processes payments and transactions Supplier Service: Manages vendor relationships and supplier data Consumer Service: Handles customer profiles and preferences  Deployment Strategy Each microservice follows a consistent deployment pattern:\n Containerization: Docker images stored in ECR ECS Fargate: Serverless container hosting Service Discovery: Automatic registration with AWS Cloud Map Health Checks: Built-in monitoring and auto-recovery Environment Configuration: Centralized config management  CDK Service Stack Structure // Example: Product Service Stack export class ProductServiceStack extends Stack { constructor(scope: Construct, id: string, props: ServiceStackProps) { super(scope, id, props); // Task Definition  const taskDefinition = new FargateTaskDefinition(this, \u0026#39;ProductTaskDef\u0026#39;, { cpu: 256, memoryLimitMiB: 512, }); // Container Definition  const container = taskDefinition.addContainer(\u0026#39;ProductContainer\u0026#39;, { image: ContainerImage.fromEcrRepository(props.ecrRepository), environment: { NODE_ENV: \u0026#39;production\u0026#39;, SERVICE_NAME: \u0026#39;product-service\u0026#39;, }, logging: LogDrivers.awsLogs({ streamPrefix: \u0026#39;product-service\u0026#39;, logGroup: new LogGroup(this, \u0026#39;ProductLogGroup\u0026#39;, { logGroupName: \u0026#39;/ecs/product-service\u0026#39;, retention: RetentionDays.ONE_WEEK, }), }), }); // ECS Service  const service = new FargateService(this, \u0026#39;ProductService\u0026#39;, { cluster: props.cluster, taskDefinition, desiredCount: 2, assignPublicIp: false, cloudMapOptions: { name: \u0026#39;product-service\u0026#39;, cloudMapNamespace: props.namespace, }, }); } } Container Image Build Process Each service includes a Dockerfile optimized for production:\n# Multi-stage build for smaller imagesFROMnode:18-alpine AS builderWORKDIR/appCOPY package*.json ./RUN npm ci --only=productionFROMnode:18-alpine AS runtimeWORKDIR/appCOPY --from=builder /app/node_modules ./node_modulesCOPY . .EXPOSE3000USERnodeCMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]Service Communication Services communicate using:\n Service Discovery: AWS Cloud Map for internal service resolution API Gateway: External client access through HTTP API Direct Service Calls: Internal REST API communication Event-Driven Architecture: Future implementation with SQS/SNS  Content 3.1. Deploy Product and Inventory Services 3.2. Deploy Order and Payment Services\n"
},
{
	"uri": "/2-prerequiste/2.1-createec2/2.1.4-createsecgroup/",
	"title": "Create security groups",
	"tags": [],
	"description": "",
	"content": "Create security groups In this step, we will proceed to create the security groups used for our instances. As you can see, these security groups will not need to open traditional ports to ssh like port 22 or remote desktop through port 3389.\nCreate security group for Linux instance located in public subnet  Go to VPC service management console   Click Security Group. Click Create security group.  In the Security group name field, enter SG Public Linux Instance.   In the Description section, enter SG Public Linux Instance. In the VPC section, click the X to reselect the Lab VPC you created for this lab.  Keep Outbound rule, drag the mouse to the bottom.   Click Create security group.  As you can see, the security group we created to use for Linux public instances will not need to open traditional ports to ssh like port 22.\n\rCreate a security group for a Windows instance located in a private subnet  After successfully creating a security group for the Linux instance located in the public subnet, click the Security Groups link to return to the Security groups list.   Click Create security group.\n  In the Security group name field, enter SG Private Windows Instance.\n   In the Description section, enter SG Private Windows Instance. In the VPC section, click the X to reselect the Lab VPC you created for this lab.  Scroll down.   Add Outbound rule to allow TCP 443 connection to 10.10.0.0/16 ( CIDR of Lab VPC we created) Click Create security group.  For the Instance in the private subnet, we will connect to the Session Manager endpoint over a TLS encrypted connection, so we need to allow outbound connection from our instance to VPC CIDR through port 443.\n\rCreate security group for VPC Endpoint  In this step, we will create security group for VPC Endpoint of Session Manager. After successfully creating the security group for the Windows instance in the private subnet, click the Security Groups link to return to the Security groups list. Click Create security group. In the Security group name field, enter SG VPC Endpoint.   In the Description section, enter SG VPC Endpoint. In the VPC section, click the X to reselect the Lab VPC you created for this lab.  Scroll down.   Delete Outbound rule.  Add Inbound rule allowing TCP 443 to come from 10.10.0.0/16 ( CIDR of Lab VPC we created ).   Click Create security group.  So we are done creating the necessary security groups for EC2 instances and VPC Endpoints.\n"
},
{
	"uri": "/4-s3log/4.4-configsessionlogs/",
	"title": "Monitor session logs",
	"tags": [],
	"description": "",
	"content": "Monitor session logs  Access System Manager - Session Manager service management console   Click the Preferences tab. Click Edit.  Scroll down, at S3 logging, click Enable.   Uncheck Allow only encrypted S3 buckets. Click Choose a bucket name from the list. Select the S3 bucket you created.   Scroll down, click Save to save the configuration.\n  Access System Manager - Session Manager service management console\n   Click Start session. Click Private Windows Instance. Click Start session.  Type the command ipconfig.   Type the command hostname. Click Terminate to exit the session, click Terminate again to confirm.  Check Session logs in S3  Go to S3 service management console   Click on the name of the S3 bucket we created for the lab.  Click on the object name sessions log  On the objects detail page, click Open.  Object logs will be opened in a new tab in the browser. You can view the stored commands in session logs.  "
},
{
	"uri": "/4-s3log/",
	"title": "Service Communication &amp; Discovery",
	"tags": [],
	"description": "",
	"content": "In this section, we\u0026rsquo;ll implement service discovery and communication patterns for our microservices. We\u0026rsquo;ll set up AWS Cloud Map for automatic service registration and configure API Gateway as the external entry point.\nService Discovery with AWS Cloud Map AWS Cloud Map provides service discovery for cloud resources. When your services are deployed to ECS, they automatically register with Cloud Map, making them discoverable by other services.\nKey Benefits:  Automatic Registration: Services register themselves when they start Health Checking: Unhealthy services are automatically removed DNS-based Discovery: Services can find each other using simple DNS queries No Load Balancer Required: Direct service-to-service communication  API Gateway Configuration Our API Gateway serves as the single entry point for external clients, routing requests to the appropriate microservices based on the URL path.\nAPI Routes Structure: /api/v1/products/* → product-service\r/api/v1/inventory/* → inventory-service /api/v1/orders/* → order-service\r/api/v1/payments/* → payment-service\r/api/v1/suppliers/* → supplier-service\r/api/v1/consumers/* → consumer-service\rCDK Implementation Cloud Map Namespace Setup: export class ServiceDiscoveryStack extends Stack { public readonly namespace: PrivateDnsNamespace; constructor(scope: Construct, id: string, props: StackProps) { super(scope, id, props); this.namespace = new PrivateDnsNamespace(this, \u0026#39;EcommerceNamespace\u0026#39;, { name: \u0026#39;ecommerce.local\u0026#39;, vpc: props.vpc, description: \u0026#39;Service discovery for e-commerce microservices\u0026#39;, }); } } API Gateway HTTP API: export class ApiGatewayStack extends Stack { constructor(scope: Construct, id: string, props: ApiGatewayStackProps) { super(scope, id, props); const httpApi = new HttpApi(this, \u0026#39;EcommerceApi\u0026#39;, { apiName: \u0026#39;ecommerce-microservices-api\u0026#39;, description: \u0026#39;HTTP API for e-commerce microservices\u0026#39;, corsPreflight: { allowOrigins: [\u0026#39;*\u0026#39;], allowMethods: [CorsHttpMethod.ANY], allowHeaders: [\u0026#39;*\u0026#39;], }, }); // Add routes for each service  this.addServiceRoutes(httpApi, props.services); } private addServiceRoutes(api: HttpApi, services: ServiceInfo[]) { services.forEach(service =\u0026gt; { const integration = new HttpServiceDiscoveryIntegration( `${service.name}Integration`, service.cloudMapService, { vpcLink: this.vpcLink, } ); api.addRoutes({ path: `/api/v1/${service.path}/{proxy+}`, methods: [HttpMethod.ANY], integration, }); }); } } Inter-Service Communication Services communicate with each other using DNS names provided by Cloud Map:\n// Example: Order service calling inventory service const inventoryServiceUrl = \u0026#39;http://inventory-service.ecommerce.local:3000\u0026#39;; async function checkInventory(productId) { const response = await fetch(`${inventoryServiceUrl}/api/inventory/${productId}`); return response.json(); } Monitoring and Observability We\u0026rsquo;ll implement comprehensive monitoring using CloudWatch:\nCloudWatch Logs:  Centralized logging for all microservices Structured JSON logs for easy parsing Custom log groups per service  CloudWatch Metrics:  Request count and response times Error rates and HTTP status codes Custom business metrics  Content:  Setup Service Discovery with Cloud Map Configure API Gateway HTTP API Implement Inter-Service Communication Setup Monitoring and Alerting  "
},
{
	"uri": "/5-portfwd/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "\rImportant: To avoid incurring unnecessary charges, make sure to clean up all resources after completing the workshop. CDK makes this process simple with the cdk destroy command.\n\rCleanup Process Since we used AWS CDK to deploy our infrastructure, cleaning up is straightforward. The CDK will handle the proper deletion order and dependencies automatically.\nStep 1: Navigate to CDK Project Directory cd ecommerce-microservices-cdk Step 2: List All Deployed Stacks First, let\u0026rsquo;s see what stacks are currently deployed:\ncdk list You should see output similar to:\nEcommerceNetworkStack\rEcommerceEcrStack EcommerceEcsStack\rEcommerceApiGatewayStack\rEcommerceMonitoringStack\rProductServiceStack\rInventoryServiceStack\rOrderServiceStack\rPaymentServiceStack\rSupplierServiceStack\rConsumerServiceStack\rStep 3: Destroy All Stacks To destroy all stacks at once:\ncdk destroy --all Or destroy stacks individually in reverse order of dependencies:\n# Destroy service stacks first cdk destroy ProductServiceStack cdk destroy InventoryServiceStack cdk destroy OrderServiceStack cdk destroy PaymentServiceStack cdk destroy SupplierServiceStack cdk destroy ConsumerServiceStack # Then destroy infrastructure stacks cdk destroy EcommerceApiGatewayStack cdk destroy EcommerceMonitoringStack cdk destroy EcommerceEcsStack cdk destroy EcommerceEcrStack cdk destroy EcommerceNetworkStack Step 4: Confirm Deletion CDK will prompt you to confirm each stack deletion. Type y to confirm:\nAre you sure you want to delete: ProductServiceStack (y/n)? y\rStep 5: Verify Cleanup After all stacks are destroyed, verify in the AWS Console that resources have been cleaned up:\n CloudFormation: Check that all stacks show DELETE_COMPLETE status ECS: Verify clusters and services are deleted ECR: Check that repositories are deleted (or empty if you want to keep them) VPC: Confirm VPC and associated resources are removed CloudWatch: Log groups may remain - delete manually if needed  Optional: Clean Up ECR Images If you want to keep the ECR repositories but clean up the images:\n# List repositories aws ecr describe-repositories # Delete all images in a repository aws ecr batch-delete-image \\  --repository-name product-service \\  --image-ids imageTag=latest Manual Cleanup (If Needed) In rare cases, some resources might not be deleted automatically. Check these services manually:\n S3 Buckets: Delete any remaining buckets and their contents CloudWatch Log Groups: Remove log groups if they persist IAM Roles: Clean up any orphaned IAM roles Security Groups: Remove any lingering security groups  Cost Verification Finally, check AWS Cost Explorer to ensure no unexpected charges:\n Go to AWS Cost Explorer Set the time range to cover your workshop period Verify that costs stop accumulating after resource deletion  Troubleshooting Cleanup Issues If you encounter issues during cleanup:\nStack Deletion Failed # Check the CloudFormation console for error details # Common issues: Resources still in use, dependency conflicts # Force delete after resolving dependencies cdk destroy StackName --force ECR Repository Not Empty # Delete all images first aws ecr list-images --repository-name service-name aws ecr batch-delete-image --repository-name service-name --image-ids imageTag=tag VPC Deletion Failed # Usually due to remaining network interfaces or security group dependencies # Check EC2 console for any remaining ENIs or security groups Summary Using AWS CDK for infrastructure deployment makes cleanup much simpler compared to manual resource creation. The cdk destroy command handles dependencies automatically and ensures proper cleanup order.\nRemember: Always verify that all resources are properly deleted to avoid unexpected charges!\n Click Attach existing policies directly.\n In the search box, enter ssm. Click on AmazonSSMFullAccess. Click Next: Tags, click Next: Reviews. Click Create user.    Save Access key ID and Secret access key information to perform AWS CLI configuration.\n  Install and Configure AWS CLI and Session Manager Plugin To perform this hands-on, make sure your workstation has AWS CLI and Session Manager Plugin installed -manager-working-with-install-plugin.html)\nMore hands-on tutorials on installing and configuring the AWS CLI can be found here.\nWith Windows, when extracting the Session Manager Plugin installation folder, run the install.bat file with Administrator permission to perform the installation.\n\rImplement Portforwarding  Run the command below in Command Prompt on your machine to configure Port Forwarding.   aws ssm start-session --target (your ID windows instance) --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026quot;3389\u0026quot;,localPortNumber=\u0026quot;9999\u0026quot; --region (your region)\r\rWindows Private Instance Instance ID information can be found when you view the EC2 Windows Private Instance server details.\n\r Example command:  C:\\Windows\\system32\u0026gt;aws ssm start-session --target i-06343d7377486760c --document-name AWS-StartPortForwardingSession --parameters portNumber=\u0026quot;3389\u0026quot;,localPortNumber=\u0026quot;9999\u0026quot; --region ap-southeast-1\r\rIf your command gives an error like below: SessionManagerPlugin is not found. Please refer to SessionManager Documentation here: http://docs.aws.amazon.com/console/systems-manager/session-manager-plugin-not-found\nProve that you have not successfully installed the Session Manager Plugin. You may need to relaunch Command Prompt after installing Session Manager Plugin.\n\rConnect to the Private Windows Instance you created using the Remote Desktop tool on your workstation.  In the Computer section: enter localhost:9999.    Return to the administration interface of the System Manager - Session Manager service.  Click tab Session history. We will see session logs with Document name AWS-StartPortForwardingSession.    Congratulations on completing the lab on how to use Session Manager to connect and store session logs in S3 bucket. Remember to perform resource cleanup to avoid unintended costs.\n"
},
{
	"uri": "/2-prerequiste/2.1-createec2/2.1.5-createec2linux/",
	"title": "Create Public instance",
	"tags": [],
	"description": "",
	"content": " Go to EC2 service management console   Click Instances. Click Launch instances.  On the Step 1: Choose an Amazon Machine Image (AMI) page.   Click Select to select AMI Amazon Linux 2 AMI.  On the Step 2: Choose an Instance Type page.   Click on Instance type t2.micro. Click Next: Configure Instance Details.  At Step 3: Configure Instance Details page   In the Network section, select Lab VPC. In the Subnet section, select Lab Public Subnet. In the Auto-assign Public IP section, select Use subnet setting (Enable) Click Next: Add Storage.  Click Next: Add Tags to move to the next step.   Click Next: Configure Security Group to move to the next step.  On page Step 6: Configure Security Group.   Select Select an existing security group. Select security group SG Public Linux Instance. Click Review and Launch.   The warning dialog box appears because we do not configure the firewall to allow connections to port 22, Click Continue to continue.\n  At page Step 7: Review Instance Launch.\n   Click Launch.  In the Select an existing key pair or create a new key pair dialog box.   Click to select Create a new key pair. In the Key pair name field, enter LabKeypair. Click Download Key Pair and save it to your computer. Click Launch Instances to create EC2 server.   Click View Instances to return to the list of EC2 instances.\n  Click the edit icon under the Name column.\n   In the Edit Name dialog box, enter Public Linux Instance. Click Save.  Next, we will do the same to create an EC2 Instance Windows running in the Private subnet.\n"
},
{
	"uri": "/2-prerequiste/2.1-createec2/2.1.6-createec2windows/",
	"title": "Create Private Instance",
	"tags": [],
	"description": "",
	"content": " Go to EC2 service management console   Click Instances. Click Launch instances.  On the Step 1: Choose an Amazon Machine Image (AMI) page.   Drag the mouse down. Click Select to select AMI Microsoft Windows Server 2019 Base.  On the Step 2: Choose an Instance Type page.   Click on Instance type t2.micro. Click Next: Configure Instance Details.  At Step 3: Configure Instance Details page   In the Network section, select Lab VPC. In the Subnet section, select Lab Private Subnet. At Auto-assign Public IP select Use subnet setting (Disable) Click Next: Add Storage.  Click Next: Add Tags to move to the next step.   Click Next: Configure Security Group to move to the next step.  On page Step 6: Configure Security Group.   Select Select an existing security group. Select security group SG Private Windows Instance. Click Review and Launch.   The warning dialog box appears because we do not configure the firewall to allow connections to port 22, Click Continue to continue.\n  At page Step 7: Review Instance Launch.\n   Click Launch.  In the Select an existing key pair or create a new key pair dialog box.   Click Choose an existing key pair. In the Key pair name section, select LabKeypair. Click I acknowledge that I have access to the corresponding private key file, and that without this file, I won\u0026rsquo;t be able to log into my instance.. Click Launch Instances to create EC2 server.   Click View Instances to return to the list of EC2 instances.\n  Click the edit icon under the Name column.\n   In the Edit Name dialog box, enter Private Windows Instance. Click Save.  Next, we will proceed to create IAM Roles to serve the Session Manager.\n"
},
{
	"uri": "/cdk-setup-guide/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "E-commerce Microservices CDK Setup Guide Quick Start This guide will help you set up the CDK infrastructure for our e-commerce microservices workshop.\nPrerequisites  AWS CLI configured with appropriate permissions Node.js (v16 or later) AWS CDK installed globally Docker for building container images  Installation Steps 1. Install AWS CDK npm install -g aws-cdk 2. Verify Installation cdk --version 3. Bootstrap CDK (First time only) cdk bootstrap aws://ACCOUNT-NUMBER/REGION Project Structure ecommerce-microservices-cdk/\r├── bin/\r│ └── app.ts # CDK App entry point\r├── lib/\r│ ├── stacks/\r│ │ ├── network-stack.ts # VPC, subnets, security groups\r│ │ ├── ecr-stack.ts # Container repositories\r│ │ ├── ecs-stack.ts # ECS cluster\r│ │ ├── api-gateway-stack.ts # API Gateway HTTP API\r│ │ └── monitoring-stack.ts # CloudWatch logs and metrics\r│ └── constructs/\r│ └── microservice.ts # Reusable microservice construct\r├── services/\r│ ├── product-service/\r│ ├── inventory-service/\r│ ├── order-service/\r│ ├── payment-service/\r│ ├── supplier-service/\r│ └── consumer-service/\r├── cdk.json\r├── package.json\r└── README.md\rCDK Commands Deploy all stacks cdk deploy --all Deploy specific stack cdk deploy NetworkStack List all stacks cdk list Show differences cdk diff Synthesize CloudFormation cdk synth Destroy all resources cdk destroy --all Environment Variables Create a .env file in the project root:\n# AWS Configuration AWS_ACCOUNT=123456789012 AWS_REGION=us-east-1 # Application Configuration APP_NAME=ecommerce-microservices ENVIRONMENT=dev # Container Configuration ECR_REPOSITORY_PREFIX=ecommerce CONTAINER_CPU=256 CONTAINER_MEMORY=512 # Network Configuration VPC_CIDR=10.0.0.0/16 Key CDK Constructs Used 1. Network Stack  VPC with public/private subnets Internet Gateway and NAT Gateway Security Groups for services VPC Endpoints for AWS services  2. Container Stack  ECR repositories for each service ECS Fargate cluster Service discovery namespace Task definitions and services  3. API Gateway Stack  HTTP API Gateway VPC Link for private integration Routes for each microservice CORS configuration  4. Monitoring Stack  CloudWatch Log Groups Custom metrics and dashboards Alarms for critical metrics  Service Discovery Services are registered automatically with AWS Cloud Map:\nconst service = new FargateService(this, \u0026#39;ProductService\u0026#39;, { cluster: props.cluster, taskDefinition, cloudMapOptions: { name: \u0026#39;product-service\u0026#39;, cloudMapNamespace: props.namespace, }, }); Inter-Service Communication Services communicate using DNS names:\n// Product service URL const productServiceUrl = \u0026#39;http://product-service.ecommerce.local:3000\u0026#39;; // API call const response = await fetch(`${productServiceUrl}/api/products`); Monitoring and Logging All services automatically log to CloudWatch:\nlogging: LogDrivers.awsLogs({ streamPrefix: \u0026#39;product-service\u0026#39;, logGroup: new LogGroup(this, \u0026#39;ProductLogGroup\u0026#39;, { logGroupName: \u0026#39;/ecs/product-service\u0026#39;, retention: RetentionDays.ONE_WEEK, }), }), Security Best Practices  IAM Roles: Least privilege access for each service Security Groups: Restricted network access VPC: Private subnets for services Secrets Manager: Sensitive configuration data  Troubleshooting Common Issues:   Bootstrap Required\ncdk bootstrap aws://ACCOUNT/REGION   ECR Repository Already Exists\n Delete existing repositories or use different names    VPC Limits\n Check VPC quotas in AWS console    IAM Permissions\n Ensure CDK has necessary permissions    Cost Optimization  Use Fargate Spot for non-production workloads Enable auto-scaling for services Set appropriate log retention periods Use reserved capacity for predictable workloads  Next Steps  Complete the CDK setup Build and push container images Deploy the infrastructure Test service communication Monitor and optimize  For detailed implementation, follow the workshop sections in order.\n"
},
{
	"uri": "/productservice-implementation/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Product Service Implementation Overview The Product Service is responsible for managing the product catalog in our e-commerce microservices architecture. It handles product information, categories, pricing, and metadata.\nAPI Endpoints GET /api/v1/products List all products with pagination and filtering capabilities.\nQuery Parameters:\n page (optional): Page number (default: 1) limit (optional): Items per page (default: 20, max: 100) category (optional): Filter by category search (optional): Search term for product names/descriptions minPrice (optional): Minimum price filter maxPrice (optional): Maximum price filter  Response:\n{ \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;prod-001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Wireless Bluetooth Headphones\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;High-quality wireless headphones with noise cancellation\u0026#34;, \u0026#34;price\u0026#34;: 99.99, \u0026#34;category\u0026#34;: \u0026#34;Electronics\u0026#34;, \u0026#34;imageUrl\u0026#34;: \u0026#34;https://example.com/images/headphones.jpg\u0026#34;, \u0026#34;inStock\u0026#34;: true, \u0026#34;supplierId\u0026#34;: \u0026#34;sup-001\u0026#34;, \u0026#34;createdAt\u0026#34;: \u0026#34;2024-01-15T10:30:00Z\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2024-01-20T15:45:00Z\u0026#34; } ], \u0026#34;pagination\u0026#34;: { \u0026#34;page\u0026#34;: 1, \u0026#34;limit\u0026#34;: 20, \u0026#34;total\u0026#34;: 150, \u0026#34;totalPages\u0026#34;: 8 } } GET /api/v1/products/{id} Get detailed information about a specific product.\nResponse:\n{ \u0026#34;id\u0026#34;: \u0026#34;prod-001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Wireless Bluetooth Headphones\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;High-quality wireless headphones with noise cancellation features. Perfect for music lovers and professionals.\u0026#34;, \u0026#34;price\u0026#34;: 99.99, \u0026#34;category\u0026#34;: \u0026#34;Electronics\u0026#34;, \u0026#34;subcategory\u0026#34;: \u0026#34;Audio\u0026#34;, \u0026#34;imageUrls\u0026#34;: [ \u0026#34;https://example.com/images/headphones-1.jpg\u0026#34;, \u0026#34;https://example.com/images/headphones-2.jpg\u0026#34; ], \u0026#34;specifications\u0026#34;: { \u0026#34;brand\u0026#34;: \u0026#34;TechAudio\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;TA-BT500\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;Black\u0026#34;, \u0026#34;weight\u0026#34;: \u0026#34;250g\u0026#34;, \u0026#34;batteryLife\u0026#34;: \u0026#34;30 hours\u0026#34; }, \u0026#34;inStock\u0026#34;: true, \u0026#34;supplierId\u0026#34;: \u0026#34;sup-001\u0026#34;, \u0026#34;supplierName\u0026#34;: \u0026#34;Tech Components Ltd\u0026#34;, \u0026#34;ratings\u0026#34;: { \u0026#34;average\u0026#34;: 4.5, \u0026#34;count\u0026#34;: 127 }, \u0026#34;createdAt\u0026#34;: \u0026#34;2024-01-15T10:30:00Z\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2024-01-20T15:45:00Z\u0026#34; } POST /api/v1/products (Admin Only) Create a new product.\nRequest Body:\n{ \u0026#34;name\u0026#34;: \u0026#34;Wireless Mouse\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Ergonomic wireless mouse with precision tracking\u0026#34;, \u0026#34;price\u0026#34;: 29.99, \u0026#34;category\u0026#34;: \u0026#34;Electronics\u0026#34;, \u0026#34;subcategory\u0026#34;: \u0026#34;Computer Accessories\u0026#34;, \u0026#34;imageUrls\u0026#34;: [\u0026#34;https://example.com/images/mouse.jpg\u0026#34;], \u0026#34;specifications\u0026#34;: { \u0026#34;brand\u0026#34;: \u0026#34;ComputerPro\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;CP-WM200\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;Silver\u0026#34;, \u0026#34;connectivity\u0026#34;: \u0026#34;2.4GHz Wireless\u0026#34; }, \u0026#34;supplierId\u0026#34;: \u0026#34;sup-002\u0026#34; } Docker Configuration Dockerfile FROMnode:18-alpineWORKDIR/appCOPY package*.json ./RUN npm ci --only=productionCOPY . .EXPOSE3000USERnodeCMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;]docker-compose.yml (for local development) version: \u0026#39;3.8\u0026#39; services: product-service: build: . ports: - \u0026#34;3001:3000\u0026#34; environment: - NODE_ENV=development - DB_HOST=product-db - DB_PORT=5432 - DB_NAME=products - DB_USER=productuser - DB_PASSWORD=productpass - REDIS_URL=redis://redis:6379 depends_on: - product-db - redis product-db: image: postgres:15-alpine environment: - POSTGRES_DB=products - POSTGRES_USER=productuser - POSTGRES_PASSWORD=productpass volumes: - product_db_data:/var/lib/postgresql/data redis: image: redis:7-alpine ports: - \u0026#34;6379:6379\u0026#34; volumes: product_db_data: ECS Task Definition { \u0026#34;family\u0026#34;: \u0026#34;product-service\u0026#34;, \u0026#34;networkMode\u0026#34;: \u0026#34;awsvpc\u0026#34;, \u0026#34;requiresCompatibilities\u0026#34;: [\u0026#34;FARGATE\u0026#34;], \u0026#34;cpu\u0026#34;: \u0026#34;256\u0026#34;, \u0026#34;memory\u0026#34;: \u0026#34;512\u0026#34;, \u0026#34;executionRoleArn\u0026#34;: \u0026#34;arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole\u0026#34;, \u0026#34;taskRoleArn\u0026#34;: \u0026#34;arn:aws:iam::ACCOUNT:role/ecsTaskRole\u0026#34;, \u0026#34;containerDefinitions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;product-service\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;ACCOUNT.dkr.ecr.REGION.amazonaws.com/product-service:latest\u0026#34;, \u0026#34;portMappings\u0026#34;: [ { \u0026#34;containerPort\u0026#34;: 3000, \u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34; } ], \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;NODE_ENV\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;production\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;DB_HOST\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;product-db.cluster-xyz.us-east-1.rds.amazonaws.com\u0026#34; } ], \u0026#34;secrets\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;DB_PASSWORD\u0026#34;, \u0026#34;valueFrom\u0026#34;: \u0026#34;arn:aws:secretsmanager:us-east-1:ACCOUNT:secret:product-db-password\u0026#34; } ], \u0026#34;logConfiguration\u0026#34;: { \u0026#34;logDriver\u0026#34;: \u0026#34;awslogs\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;awslogs-group\u0026#34;: \u0026#34;/ecs/product-service\u0026#34;, \u0026#34;awslogs-region\u0026#34;: \u0026#34;us-east-1\u0026#34;, \u0026#34;awslogs-stream-prefix\u0026#34;: \u0026#34;ecs\u0026#34; } }, \u0026#34;healthCheck\u0026#34;: { \u0026#34;command\u0026#34;: [\u0026#34;CMD-SHELL\u0026#34;, \u0026#34;curl -f http://localhost:3000/health || exit 1\u0026#34;], \u0026#34;interval\u0026#34;: 30, \u0026#34;timeout\u0026#34;: 5, \u0026#34;retries\u0026#34;: 3, \u0026#34;startPeriod\u0026#34;: 60 } } ] } Database Schema (PostgreSQL) CREATE TABLE products ( id VARCHAR(50) PRIMARY KEY, name VARCHAR(255) NOT NULL, description TEXT, price DECIMAL(10, 2) NOT NULL, category VARCHAR(100) NOT NULL, subcategory VARCHAR(100), image_urls TEXT[], specifications JSONB, supplier_id VARCHAR(50) NOT NULL, in_stock BOOLEAN DEFAULT true, created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(), updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() ); CREATE INDEX idx_products_category ON products(category); CREATE INDEX idx_products_supplier ON products(supplier_id); CREATE INDEX idx_products_price ON products(price); CREATE INDEX idx_products_name ON products USING gin(to_tsvector(\u0026#39;english\u0026#39;, name)); Health Check Endpoint GET /health { \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2024-01-20T16:30:00Z\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;product-service\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;database\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;redis\u0026#34;: \u0026#34;healthy\u0026#34; } } Monitoring and Observability CloudWatch Metrics  Request count per endpoint Response time percentiles Error rates Database connection pool status  Log Format (JSON) { \u0026#34;timestamp\u0026#34;: \u0026#34;2024-01-20T16:30:00Z\u0026#34;, \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;product-service\u0026#34;, \u0026#34;traceId\u0026#34;: \u0026#34;abc-123-def\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Product retrieved successfully\u0026#34;, \u0026#34;productId\u0026#34;: \u0026#34;prod-001\u0026#34;, \u0026#34;responseTime\u0026#34;: 45 } "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]